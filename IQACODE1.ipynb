{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ef33eda",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn; sn.set(font_scale=1.4)\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "import random\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers import Conv2D, Flatten\n",
    "from keras.layers import Reshape, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "\n",
    "seed = 21\n",
    "random.seed = seed\n",
    "np.random.seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67388611",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_frames = 'sharp dataset'\n",
    "bad_frames = 'noisy dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d956f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_frames = []\n",
    "for file in tqdm(sorted(os.listdir(clear_frames))):\n",
    "    if any(extension in file for extension in ['.jpg', 'jpeg', '.png']):\n",
    "        image = tf.keras.preprocessing.image.load_img(clear_frames + '/' + file, target_size=(128,128))\n",
    "        image = tf.keras.preprocessing.image.img_to_array(image).astype('float32') / 255\n",
    "        clean_frames.append(image)\n",
    "\n",
    "clean_frames = np.array(clean_frames)\n",
    "blurry_frames = []\n",
    "for file in tqdm(sorted(os.listdir(bad_frames))):\n",
    "    if any(extension in file for extension in ['.jpg', 'jpeg', '.png']):\n",
    "        image = tf.keras.preprocessing.image.load_img(bad_frames + '/' + file, target_size=(128,128))\n",
    "        image = tf.keras.preprocessing.image.img_to_array(image).astype('float32') / 255\n",
    "        blurry_frames.append(image)\n",
    "\n",
    "blurry_frames = np.array(blurry_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd05fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['noisy dataset','sharp dataset']\n",
    "class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "nb_classes = len(class_names)\n",
    "\n",
    "IMAGE_SIZE = (128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d6806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C:\\Users\\onlin\\Downloads\\archive\\dataset\n",
    "def load_data():\n",
    "\n",
    "    datasets = ['C:/Users/tdpra/OneDrive/Desktop/Jupyter python/IMG QUAL/dataset/train', 'C:/Users/tdpra/OneDrive/Desktop/Jupyter python/IMG QUAL/dataset/test']\n",
    "\n",
    "    output = []\n",
    "\n",
    "    # Iterate through training and test sets\n",
    "    for dataset in datasets:\n",
    "\n",
    "        images = []\n",
    "        labels = []\n",
    "\n",
    "        print(\"Loading {}\".format(dataset))\n",
    "\n",
    "        # Iterate through each folder corresponding to a category\n",
    "        for folder in os.listdir(dataset):\n",
    "            label = class_names_label[folder]\n",
    "\n",
    "            # Iterate through each image in our folder\n",
    "            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n",
    "\n",
    "                # Get the path name of the image\n",
    "                img_path = os.path.join(os.path.join(dataset, folder), file)\n",
    "\n",
    "                # Open and resize the img\n",
    "                image = cv2.imread(img_path)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image = cv2.resize(image, IMAGE_SIZE)\n",
    "\n",
    "                # Append the image and its corresponding label to the output\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "\n",
    "        images = np.array(images, dtype = 'float32')\n",
    "        labels = np.array(labels, dtype = 'int32')\n",
    "\n",
    "        output.append((images, labels))\n",
    "\n",
    "    return output   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72affb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16c883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = random.randint(0, len(clean_frames)-1)\n",
    "print(r)\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.2)\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.imshow(clean_frames[r])\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.imshow(blurry_frames[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f043c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = train_labels.shape[0]\n",
    "n_test = test_labels.shape[0]\n",
    "\n",
    "print (\"Number of training examples: {}\".format(n_train))\n",
    "print (\"Number of testing examples: {}\".format(n_test))\n",
    "print (\"Each image is of size: {}\".format(IMAGE_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b6a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "_, train_counts = np.unique(train_labels, return_counts=True)\n",
    "_, test_counts = np.unique(test_labels, return_counts=True)\n",
    "pd.DataFrame({'train': train_counts,\n",
    "                    'test': test_counts},\n",
    "             index=class_names\n",
    "            ).plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59881422",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe2efe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_examples(class_names, images, labels):\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    fig.suptitle(\"images of the dataset\", fontsize=16)\n",
    "    for i in range(5):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i], cmap=plt.cm.binary)\n",
    "        plt.xlabel(class_names[labels[i]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb2db23",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_examples(class_names, train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa77083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "input_shape = (128,128, 3)\n",
    "batch_size = 32\n",
    "kernel_size = 3\n",
    "latent_dim = 256\n",
    "layer_filters = [64, 128, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de92fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape = input_shape, name = 'encoder_input')\n",
    "x = inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0342d000",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filters in layer_filters:\n",
    "    x = Conv2D(filters=filters,\n",
    "               kernel_size=kernel_size,\n",
    "               strides=2,\n",
    "               activation='relu',\n",
    "               padding='same')(x)\n",
    "shape = K.int_shape(x)\n",
    "x = Flatten()(x)\n",
    "latent = Dense(latent_dim, name='latent_vector')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6902787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(inputs, latent, name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c150b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\n",
    "x = Dense(shape[1]*shape[2]*shape[3])(latent_inputs)\n",
    "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "for filters in layer_filters[::-1]:\n",
    "    x = Conv2DTranspose(filters=filters,\n",
    "                        kernel_size=kernel_size,\n",
    "                        strides=2,\n",
    "                        activation='relu',\n",
    "                        padding='same')(x)\n",
    "\n",
    "outputs = Conv2DTranspose(filters=3,\n",
    "                          kernel_size=kernel_size,\n",
    "                          activation='sigmoid',\n",
    "                          padding='same',\n",
    "                          name='decoder_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e11d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f32d78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs, decoder(encoder(inputs)), name='autoencoder')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82dc10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam',metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ace1e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               verbose=1,\n",
    "                               min_lr=0.5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48de007",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [lr_reducer]\n",
    "history = model.fit(blurry_frames,\n",
    "                      clean_frames,\n",
    "                      validation_data=(blurry_frames, clean_frames),\n",
    "                      epochs=20,\n",
    "                      batch_size=batch_size,\n",
    "                      callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d22df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n       Input image                       quality image                  noisy image\")\n",
    "for i in range(3):\n",
    "    \n",
    "    r = random.randint(0, len(clean_frames)-1)\n",
    "\n",
    "    x, y = blurry_frames[r],clean_frames[r]\n",
    "    x_inp=x.reshape(1,128,128,3)\n",
    "    result = model.predict(x_inp)\n",
    "    result = result.reshape(128,128,3)\n",
    "\n",
    "    fig = plt.figure(figsize=(12,10))\n",
    "    fig.subplots_adjust(hspace=0.1, wspace=0.2)\n",
    "\n",
    "    ax = fig.add_subplot(1, 3, 1)\n",
    "    ax.imshow(x)\n",
    "\n",
    "    ax = fig.add_subplot(1, 3, 2)\n",
    "    ax.imshow(y)\n",
    "\n",
    "    ax = fig.add_subplot(1, 3, 3)\n",
    "    plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8cf11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.xlabel('Epoches')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(np.arange(0, 101, 25))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b193bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.xlabel('Epoches')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(np.arange(0, 101, 25))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f188796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
